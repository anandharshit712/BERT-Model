{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2eb72d6-ee16-42be-9b5a-6da31621ae18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e8837f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"email.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aeaa2f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\nth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\n( see a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: neon retreat\\nho ho ho , we ' re arou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : indian springs\\nthis deal is to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Subject: enron methanol ; meter # : 988291\\nth...\n",
       "1   ham  Subject: hpl nom for january 9 , 2001\\n( see a...\n",
       "2   ham  Subject: neon retreat\\nho ho ho , we ' re arou...\n",
       "3  spam  Subject: photoshop , windows , office . cheap ...\n",
       "4   ham  Subject: re : indian springs\\nthis deal is to ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fb96dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "ham     3672\n",
       "spam    1499\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff61dc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spam = data[data['label'] == 'spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd98cdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ham = data[data['label'] == 'ham']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "91fa7f9d",
   "metadata": {},
   "source": [
    "as the number of ham is more therefore balancing of the dataset is needed so in this case we will reduce the numeber of ham class to be equal to spam class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d33c84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ham_reduced = df_ham.sample(df_spam.shape[0])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "702f2518",
   "metadata": {},
   "source": [
    "Now the classes are balanced so concatinating the classes to a new dataframe: df_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38a10aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced = pd.concat([df_ham_reduced, df_spam])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e5c4547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "ham     1499\n",
       "spam    1499\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42c75845",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced['num_label'] = df_balanced['label'].apply(lambda x: 1 if x == 'spam' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c119b3c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>num_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : e mail list for class\\nplease re...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1692</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: fw : guadalupe power partners\\nfyi\\n-...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: july pricing discrepancy : sell to te...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: works wondder\\ndear sir / madam .\\nwe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3741</th>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: save up to 89 % on ink + no shipping ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text  num_label\n",
       "171    ham  Subject: re : e mail list for class\\nplease re...          0\n",
       "1692   ham  Subject: fw : guadalupe power partners\\nfyi\\n-...          0\n",
       "357    ham  Subject: july pricing discrepancy : sell to te...          0\n",
       "1407  spam  Subject: works wondder\\ndear sir / madam .\\nwe...          1\n",
       "3741  spam  Subject: save up to 89 % on ink + no shipping ...          1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced.sample(5)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "631a4e67",
   "metadata": {},
   "source": [
    "Splliting the balanced dataset into training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9776863",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5435e81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Harshit Anand\\.conda\\envs\\py35\\lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "C:\\Users\\Harshit Anand\\.conda\\envs\\py35\\lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_balanced['text'], df_balanced['num_label'],stratify = df_balanced['num_label'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "734edffe",
   "metadata": {},
   "source": [
    "using stratify to ensure equal distribution of ham and spam email after splliting"
   ]
  },
  {
   "cell_type": "raw",
   "id": "44e9a8c1",
   "metadata": {},
   "source": [
    "bert model is usually pre-trained. tensorflow-hub cantains cantains all the pre-trained machine learing models"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c6dfaf8f",
   "metadata": {},
   "source": [
    "now downloading 2 models one for preprocessing of the data and the other one for encoding the data to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "503c676d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    }
   ],
   "source": [
    "bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
    "bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e5a83848",
   "metadata": {},
   "source": [
    "Initializing BERT layers\n",
    "bert layers cantains preprocessing and encodeing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a6d7490",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tf.keras.layers.Input(shape = (), dtype = tf.string, name = 'text')\n",
    "preprocessed_text = bert_preprocess(input)\n",
    "outputs = bert_encoder(preprocessed_text)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "565ebe27",
   "metadata": {},
   "source": [
    "Initializing the neural network layers\n",
    "here taking 2 layers:\n",
    "1> to prevent overfitting named as Dropout\n",
    "2> this is the output layer named as Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3fb54060",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = tf.keras.layers.Dropout(0.1, name = \"Dropout\")(outputs['pooled_output'])\n",
    "l = tf.keras.layers.Dense(1, activation='sigmoid', name=\"output\")(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99fe46f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs = [input], outputs = [l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d357e0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " text (InputLayer)              [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " keras_layer (KerasLayer)       {'input_word_ids':   0           ['text[0][0]']                   \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_mask': (Non                                               \n",
      "                                e, 128),                                                          \n",
      "                                 'input_type_ids':                                                \n",
      "                                (None, 128)}                                                      \n",
      "                                                                                                  \n",
      " keras_layer_1 (KerasLayer)     {'pooled_output': (  109482241   ['keras_layer[0][0]',            \n",
      "                                None, 768),                       'keras_layer[0][1]',            \n",
      "                                 'encoder_outputs':               'keras_layer[0][2]']            \n",
      "                                 [(None, 128, 768),                                               \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768)],                                               \n",
      "                                 'sequence_output':                                               \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 'default': (None,                                                \n",
      "                                768)}                                                             \n",
      "                                                                                                  \n",
      " Dropout (Dropout)              (None, 768)          0           ['keras_layer_1[0][13]']         \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1)            769         ['Dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,483,010\n",
      "Trainable params: 769\n",
      "Non-trainable params: 109,482,241\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "31d046a8",
   "metadata": {},
   "source": [
    "Model Compiling\n",
    "here using optimizer to improve the model performance and reduuce errors that occures during the training, here using adam optimizer\n",
    "here also using metrics to check the model performance to se how the model was trained. here we use BinaryAccuracy to calculate accuracy score of the model\n",
    "here loss function is used to calculate model error during training phase. here we use binary_crossentropy as our loss function as the outpus is binary i.e. 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6dfa3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "    tf.keras.metrics.BinaryAccuracy(name = 'accuracy'),\n",
    "    tf.keras.metrics.Precision(name = 'precision'),\n",
    "    tf.keras.metrics.Recall(name = 'recall')\n",
    "]\n",
    "model.compile(optimizer = 'adam',\n",
    "               loss = 'binary_crossentropy',\n",
    "               metrics = METRICS)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6e1d3849",
   "metadata": {},
   "source": [
    "Fitting MOdel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c74629ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "71/71 [==============================] - 284s 4s/step - loss: 0.6519 - accuracy: 0.6174 - precision: 0.6252 - recall: 0.5863\n",
      "Epoch 2/10\n",
      "71/71 [==============================] - 274s 4s/step - loss: 0.5613 - accuracy: 0.7140 - precision: 0.7123 - recall: 0.7180\n",
      "Epoch 3/10\n",
      "71/71 [==============================] - 276s 4s/step - loss: 0.5138 - accuracy: 0.7478 - precision: 0.7553 - recall: 0.7331\n",
      "Epoch 4/10\n",
      "71/71 [==============================] - 276s 4s/step - loss: 0.4757 - accuracy: 0.7945 - precision: 0.7961 - recall: 0.7918\n",
      "Epoch 5/10\n",
      "71/71 [==============================] - 274s 4s/step - loss: 0.4584 - accuracy: 0.8025 - precision: 0.8080 - recall: 0.7936\n",
      "Epoch 6/10\n",
      "71/71 [==============================] - 274s 4s/step - loss: 0.4220 - accuracy: 0.8394 - precision: 0.8446 - recall: 0.8319\n",
      "Epoch 7/10\n",
      "71/71 [==============================] - 278s 4s/step - loss: 0.4077 - accuracy: 0.8545 - precision: 0.8639 - recall: 0.8416\n",
      "Epoch 8/10\n",
      "71/71 [==============================] - 273s 4s/step - loss: 0.3883 - accuracy: 0.8599 - precision: 0.8533 - recall: 0.8692\n",
      "Epoch 9/10\n",
      "71/71 [==============================] - 273s 4s/step - loss: 0.3789 - accuracy: 0.8648 - precision: 0.8674 - recall: 0.8612\n",
      "Epoch 10/10\n",
      "71/71 [==============================] - 275s 4s/step - loss: 0.3772 - accuracy: 0.8577 - precision: 0.8564 - recall: 0.8594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x232f2d369e0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c90b3d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 93s 4s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0,\n",
       "       0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1,\n",
       "       0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted = model.predict(x_test)\n",
    "y_predicted = y_predicted.flatten()\n",
    "y_predicted = np.where(y_predicted > 0.5,1,0)\n",
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a266792",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dataset = [\n",
    " \"You can win a lot of money, register in the link below\",\n",
    " \"You have an iPhone 10, spin the image below to claim your prize and it will be delivered in your door step\",\n",
    " \"You have an offer, the company will give you 50% off on every item purchased.\",\n",
    " \"Hey Bravin, don't be late for the meeting tomorrow will start lot exactly 10:30 am\",\n",
    " \"See you monday, we have alot to talk about the future of this company .\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a7a3da59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 606ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict(sample_dataset)\n",
    "prediction = np.where(prediction > 0.5, 1, 0)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c33a4b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
